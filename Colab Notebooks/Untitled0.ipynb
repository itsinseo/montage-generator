{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIc6BPLL4/gUeRWHuOLqbd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMHKTnpL3Bor","executionInfo":{"status":"ok","timestamp":1636262968092,"user_tz":-540,"elapsed":15778,"user":{"displayName":"김인서","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03765459920034352817"}},"outputId":"3c71f4bd-62a7-4aab-eeb3-5425f2c1c582"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8bPq49228S9","executionInfo":{"status":"ok","timestamp":1636262969488,"user_tz":-540,"elapsed":253,"user":{"displayName":"김인서","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03765459920034352817"}},"outputId":"9a6088f2-2913-4b59-ba82-fe46df2a70c1"},"source":["%cd /content/gdrive/MyDrive/"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jF609Qlm3Whd","executionInfo":{"status":"ok","timestamp":1636263028907,"user_tz":-540,"elapsed":58303,"user":{"displayName":"김인서","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03765459920034352817"}},"outputId":"4bbc52d4-01cd-48c0-9b9a-615aebcd5181"},"source":["%%time\n","%tensorflow_version 1.x\n","!pip install tensorflow-gpu==1.14\n","import os\n","import math\n","import pickle\n","import imageio\n","import PIL.Image\n","import numpy as np\n","from PIL import Image\n","import tensorflow as tf\n","from google.colab import files\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","\n","import argparse\n","from tqdm import tqdm\n","from encoder.generator_model import Generator\n","from encoder.perceptual_model import PerceptualModel"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n","Collecting tensorflow-gpu==1.14\n","  Downloading tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1 MB)\n","\u001b[K     |████████████████████████████████| 377.1 MB 9.1 kB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.37.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (3.17.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n","\u001b[K     |████████████████████████████████| 488 kB 43.5 MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.41.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (0.4.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14) (1.19.5)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 23.9 MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.14) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (3.1.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (4.8.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.14) (1.5.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.6.0)\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.4.0 which is incompatible.\n","tensorflow 1.15.2 requires tensorboard<1.16.0,>=1.15.0, but you have tensorboard 1.14.0 which is incompatible.\n","tensorflow 1.15.2 requires tensorflow-estimator==1.15.1, but you have tensorflow-estimator 1.14.0 which is incompatible.\n","kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n","Successfully installed tensorboard-2.6.0 tensorflow-estimator-2.6.0 tensorflow-gpu-1.14.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 2.77 s, sys: 838 ms, total: 3.61 s\n","Wall time: 58 s\n"]},{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"UhLK5Bvi2tWv","executionInfo":{"status":"error","timestamp":1636263497193,"user_tz":-540,"elapsed":73506,"user":{"displayName":"김인서","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03765459920034352817"}},"outputId":"ad7b2740-4cee-4715-efbc-8922f7aa9b6b"},"source":["def split_to_batches(l, n):\n","    for i in range(0, len(l), n):\n","        yield l[i:i + n]\n","\n","\n","def main():\n","    parser = argparse.ArgumentParser(description='Find latent representation of reference images using perceptual loss')\n","    parser.add_argument('--src_dir', default='/content/gdrive/MyDrive/aligned_images/')\n","    parser.add_argument('--generated_images_dir', default='/content/gdrive/MyDrive/generated_images/')\n","    parser.add_argument('--dlatent_dir', default='/content/gdrive/MyDrive/latent_representations/')\n","\n","    parser.add_argument('--network_pkl', default='/content/gdrive/MyDrive/networks/other/generator_model-stylegan2-config-f.pkl', help='Path to local copy of stylegan2-ffhq-config-f.pkl')\n","\n","    # for now it's unclear if larger batch leads to better performance/quality\n","    parser.add_argument('--batch_size', default=1, help='Batch size for generator and perceptual model', type=int)\n","\n","    # Perceptual model params\n","    parser.add_argument('--image_size', default=256, help='Size of images for perceptual model', type=int)\n","    parser.add_argument('--lr', default=1., help='Learning rate for perceptual model', type=float)\n","    parser.add_argument('--iterations', default=700, help='Number of optimization steps for each batch', type=int)\n","\n","    # Generator params\n","    parser.add_argument('--randomize_noise', default=False, help='Add noise to dlatents during optimization', type=bool)\n","    args, other_args = parser.parse_known_args()\n","\n","    ref_images = [os.path.join(args.src_dir, x) for x in os.listdir(args.src_dir)]\n","    ref_images = list(filter(os.path.isfile, ref_images))\n","\n","    if len(ref_images) == 0:\n","        raise Exception('%s is empty' % args.src_dir)\n","\n","    os.makedirs(args.generated_images_dir, exist_ok=True)\n","    os.makedirs(args.dlatent_dir, exist_ok=True)\n","\n","    # Initialize generator and perceptual model\n","    tflib.init_tf()\n","    generator_network, discriminator_network, Gs_network = pretrained_networks.load_networks(args.network_pkl)\n","\n","    generator = Generator(Gs_network, args.batch_size, randomize_noise=args.randomize_noise)\n","    perceptual_model = PerceptualModel(args.image_size, layer=9, batch_size=args.batch_size)\n","    perceptual_model.build_perceptual_model(generator.generated_image)\n","\n","    # Optimize (only) dlatents by minimizing perceptual loss between reference and generated images in feature space\n","    for images_batch in tqdm(split_to_batches(ref_images, args.batch_size), total=len(ref_images)//args.batch_size):\n","        names = [os.path.splitext(os.path.basename(x))[0] for x in images_batch]\n","\n","        perceptual_model.set_reference_images(images_batch)\n","        op = perceptual_model.optimize(generator.dlatent_variable, iterations=args.iterations, learning_rate=args.lr)\n","        pbar = tqdm(op, leave=False, total=args.iterations)\n","        for loss in pbar:\n","            pbar.set_description(' '.join(names)+' Loss: %.2f' % loss)\n","        print(' '.join(names), ' loss:', loss)\n","\n","        # Generate images from found dlatents and save them\n","        generated_images = generator.generate_images()\n","        generated_dlatents = generator.get_dlatents()\n","        for img_array, dlatent, img_name in zip(generated_images, generated_dlatents, names):\n","            img = PIL.Image.fromarray(img_array, 'RGB')\n","            img.save(os.path.join(args.generated_images_dir, f'{img_name}.png'), 'PNG')\n","            np.save(os.path.join(args.dlatent_dir, f'{img_name}.npy'), dlatent)\n","\n","        generator.reset_dlatents()\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-39c18c55c8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-39c18c55c8a0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mgenerator_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_networks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGs_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomize_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mperceptual_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptualModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mperceptual_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_perceptual_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/encoder/generator_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, batch_size, randomize_noise)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dlatents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_dlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'G_synthesis_1/_Run/concat:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_images_to_uint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchw_to_nhwc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muint8_cast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_image_uint8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaturate_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3781\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3782\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3783\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3785\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3606\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3609\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3647\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   3648\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3649\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3650\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"The name 'G_synthesis_1/_Run/concat:0' refers to a Tensor which does not exist. The operation, 'G_synthesis_1/_Run/concat', does not exist in the graph.\""]}]},{"cell_type":"code","metadata":{"id":"0I0b3tcV3Ito"},"source":[""],"execution_count":null,"outputs":[]}]}